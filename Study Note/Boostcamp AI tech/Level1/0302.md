# 03/02

### 할 일

* 마스크 착용 여부에 따라 다른 모델로 예측할 수 있는 분기 코드 작성. (`inference.py`)
* readme 작성.



### 피어세션/멘토링

* googLeNet 사용.
* CustomAugmentation 사용.
* TTA 적용.
* f1 loss 사용하면 batch size를 좀 키우는 것이 좋을 것 같음.
* ce와 f1 함께 사용. 
  * p=0.4가 최적.
  * autoML 사용 결과
* focal 사용은 성능 비슷.
* augmentation으로 normal과 incorrect의 학습 데이터 수 늘리기.
* 기본 args에서 augmentation을 적용하면 validation data에도 transform이 적용되어버림.
  * train loop에서 학습 직전에 augmentation.



### 공부한 내용

* model : ResNet18.
* 모델 총 4개 : mask_label, mask, normal, incorrect



#### Experiments

* optimizer : Adam

* lr scheduler : CosineAnnealingLR

* resize X

* epochs : 20

* ResNet18과 GoogLeNet 비교.

* 

  


##### train data augmentation

* normal과 incorrect의 학습 데이터를 augmentation을 통해 그 양을 늘려줌.
* train loop에서 모델에 학습하기 직전에 augmentation된 데이터를 추가해줌.
* 양이 4~5배정도 늘어나므로, batch size는 16으로 줄임.  (한 번에 처리되는 양을 줄임.)
* augmentation 시도
  1. GaussNoise (std = 0.1, 0.2, 0.3)
  2. CenterCrop(384x384, 224x224), Resize(256x192), Centercrop(384x384)->Resize(192x192)
  3. 2번 + GaussianNoise(std=random(0.2, 0.4, 0.6, 0.8, 1.0))
  4. 3번 + ColorJitter(0.2, 0.2, 0.2, 0.2)
  5. 2번 + ColorJitter(0.2, 0.2, 0.2, 0.2)
* incorrect는 눈에 띄는 성능 향상 없음.
* normal은 2번에서 약간의 성능 향상을 보임. (82.38 -> 84.22)

