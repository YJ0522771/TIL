# 03/10

### 할 일

* 5강 Object Detection
* 6-1강 CNN Visualization
* 심화과제 1 CNN Visualization



### 피어세션

* Object detection의 4가지 종류
* 



### 공부한 내용

#### Object Detection

* Semantic segmentation : 같은 class에 속하는 물체는 같은 것으로 분류.
* Instance, Panoptic segmentation : class가 아닌 개체 단위로 분류.
* Instance ⊂ Panoptic



* `Classification + Box Localization` : (p_class, x_min, y_min, x_max, y_max)
* 자율 주행.
* OCR (Optical Character Recognition)



##### Two-stage detector

* Gradient-based detector (ex. [Histogram of Oriented Gradient (2005)](https://ieeexplore.ieee.org/document/1467360))

  * 영상의 gradient를 기반으로 한 detector

  <img src="0310.assets/image-20220310131544788.png" alt="image-20220310131544788" style="zoom:50%;" />

  

* Selective search ([논문](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf))

  1. over segmentation (비슷한 색끼리 분할)
  2. 기준을 정의하여 비슷한 영역끼리 합침. → 반복. (그리디)
  3. bounding box 후보군 추출.



* [R-CNN (2014)](https://arxiv.org/abs/1311.2524)
  * ~2천개 정도의 영역을 추출. (ex. selective search)
  * pre-trained CNN 모델에서 분류.
  * 모든 추출 영역이 모델을 거치기 때문에 굉장히 느림.
  * selective search가 CPU에서만 가능.



* [Fast R-CNN (2015)](https://arxiv.org/abs/1504.08083)

  * 일단 영상 전체에 대한 feature를 한 번에 추출.
  * 영상 전체를 conv layer만 거침.
  * RoI (Region of Interest) : 추출된 후보 영역들.
  * RoI에 해당하는 feature map만 추출하여 resampling
  * bounding box regression : 더 정밀한 bbox 추출.
  * classification

  <img src="0310.assets/image-20220310133412143.png" alt="image-20220310133412143" style="zoom:50%;" />

  * 기존 R-CNN에 비해 최대 18배 정도 빠름.
  * region proposal로 인한(?) 성능 향상의 한계.



* [Faster R-CNN (2015)](https://arxiv.org/abs/1506.01497)

  * end-to-end object detection
    * 모든 구성이 neural network 기반.
  * IoU = intersection (교집합) / union (합집합)
    * 높을수록 두 집합이 잘 정합되었다.
  * Anchor boxes 
    * 특정 위치에서 가능할법한 box의 후보군. 미리 정해놓고 사용.
    * ground truth와의 IoU가 0.7 미만인 후보에 loss 적용. 
  * Region proposal network
    * region proposal을 제안하는 네트워크

  <img src="0310.assets/image-20220310134900066.png" alt="image-20220310134900066" style="zoom:50%;" />

  * Non-Maximum Suppression (NMS)



> https://lilianweng.github.io/posts/2017-12-31-object-recognition-part-3/



##### Single-stage detector

* 정확도보다 속도에 중점을 두어, 리얼타임이 가능하도록.
* RoI 관련이 없다.



* [YOLO (2016)](https://arxiv.org/abs/1506.02640)
  * 전체를 SxS grid로 나눔.
  * box 좌표 + confidence score + class score 예측.



* [Single Shot MultiBox Detector (SSD) (2016)](https://arxiv.org/abs/1512.02325) (??)
  * YOLO는 localization 성능이 상대적으로 떨어짐.
  * 레이어마다 다른 스케일의 bbox 고려.
  * multi-scale.



> https://lilianweng.github.io/posts/2018-12-27-object-recognition-part-4/



##### Two-stage detector vs Single-stage detector

* single-stage는 모든 영역에서 loss 계산.

  * 일반적인 영상은 배경의 영역이 더 넓다.

  * positive sample의 수가 negative에 비해 매우 적다.

  * class 불균형 문제 발생.

  * Focal loss 

    * cross-entropy의 확장
    * 오답일수록 더 sharp한 gradient를 가지게 됨.

    <img src="0310.assets/image-20220310141922845.png" alt="image-20220310141922845" style="zoom:50%;" />

* [RetinaNet (2017)](https://arxiv.org/abs/1708.02002)

  <img src="0310.assets/image-20220310142120368.png" alt="image-20220310142120368" style="zoom:50%;" />



##### Detection with Transformer

* [DETR (2020)](https://arxiv.org/abs/2005.12872)
* [Detecting objects as points (2019)](https://arxiv.org/abs/1904.07850)
  * 물체의 중심점.



---



#### CNN Visualization

* filter visualization - 첫번째 conv layer만 가능. (3채널)

<img src="0310.assets/image-20220310190853824.png" alt="image-20220310190853824" style="zoom:50%;" />



##### Analysis of model behaviors

* Nearest neighbors (NN) in a feature space
  * 유사한 데이터들끼리 나열.
  * fc layer 직전에 feature 추출. 
*  Dimensionality reduction
  * 차원축소를 통해 feature들을 2d로 맵핑.
  * t-SNE (t-distributed stochastic neighbor embedding)
  * Layer activation
  * Maximally activating patches
    * hidden node에서 가장 큰 값을 가지고 있는 부분의 근처로 patch를 뽑음.
    * 중간 레이어의 분석에 적합.
    * 원하는 레이어와 채널을 고름.
    * 최대 값의 receptive field.